In this case study, we will find and plot the distribution of word frequencies for each translation of Hamlet. Perhaps the distribution of word frequencies of Hamlet depends on the translation --- let's find out!

# DO NOT EDIT THIS CODE!



import os
import pandas as pd
import numpy as np
from collections import Counter


f = open("hamlet.txt", "r")


def read_book(title_path):
    """Read a book and return it as a string"""
    with open(title_path, "r") as current_file:
        text = current_file.read()
        text = text.replace("\n","").replace("\r","")
    return text

def count_words_fast(text):
    text = text.lower()
    skips = [".", ",", ";", ":", "'", '"', "\n", "!", "?", "(", ")","\r"]
    for ch in skips:
        text = text.replace(ch, "")
    word_counts = Counter(text.split(" "))
    return word_counts


def word_stats(word_counts):
    num_unique = len(word_counts)
    counts = word_counts.values()
    return (num_unique, counts)

def counter_words_dic(text):
    text = text.lower()
    skip = [".", ",", ";", ":", "'", '"', "\n", "!", "?", "(", ")","\r"]
    for ch in skip: 
        text = text.replace(ch," ")
    word_counter={}; 
    for word in text.split(" "):
        # We know the word
        if word in word_counter:
            word_counter[word] += 1
        else: 
            word_counter[word] = 1
    return word_counter
    
    
    _________________________________________________________________________________________________
    
    Exercise 1

In this case study, we will find and visualize summary statistics of the text of different translations of Hamlet. For this case study, 
functions count_words_fast and word_stats are already defined as in the Case 2 Videos (Videos 3.2.x).

hamlet = pd.read_csv("hamlet.csv")
hamlet = hamlet.set_index('Unnamed: 0')
hamlet
________________________________________________________________________________________________________________________

Exercise 2

In this exercise, we will summarize the text for a single translation of Hamlet in a pandas dataframe. 
language,text = hamlet.iloc[0]

counted_text = count_words_fast(text)
unique_word = counted_text.keys()
counts_d = counted_text.values()

#Making the dataframe
data = pd.DataFrame.from_dict(counted_text, orient="index").reset_index()
data.columns = ['word', 'count']


#Counting uniques words 
from collections import Counter
prob = data["count"]
Counter(prob)
_________________________________________________________________________________________________________________

Exercise 3

In this exercise, we will continue to define summary statistics for a single translation of Hamlet. 

data["length"]=list(map(len,data["word"]))
column_word=data["word"]

def word_frequency(count):
    if (count>10):
        frequency="frequent"
    elif(1<count<=10):
        frequency="infrequent"
    else:
        frequency="unique"
    return(frequency)


data["frequency"]=list(map(word_frequency,data["count"]))
mean_len = data.groupby(by = "frequency")["length"].mean()
num_word = data.groupby(by = "frequency").size()
mean_len

______________________________________________________________________________________________________________________

Exercise 4

In this exercise, we will summarize the statistics in data into a smaller pandas dataframe. 

language, text = hamlet.iloc[0]
counted_text = count_words_fast(text)

data = pd.DataFrame({
    "word": list(counted_text.keys()),
    "count": list(counted_text.values())
})

data["length"] = data["word"].apply(len)

data.loc[data["count"] > 10,  "frequency"] = "frequent"
data.loc[data["count"] <= 10, "frequency"] = "infrequent"
data.loc[data["count"] == 1,  "frequency"] = "unique"

sub_data=pd.DataFrame({"language": hamlet["language"]})

______________________________________________________________________________________________________

Exercise 5

In this exercise, we will join all the data summaries for text Hamlet translation.

def summarize_text(language, text):
    counted_text = count_words_fast(text)

    data = pd.DataFrame({
        "word": list(counted_text.keys()),
        "count": list(counted_text.values())
    })
    
    data.loc[data["count"] > 10,  "frequency"] = "frequent"
    data.loc[data["count"] <= 10, "frequency"] = "infrequent"
    data.loc[data["count"] == 1,  "frequency"] = "unique"
    
    data["length"] = data["word"].apply(len)
    
    sub_data = pd.DataFrame({
        "language": language,
        "frequency": ["frequent","infrequent","unique"],
        "mean_word_length": data.groupby(by = "frequency")["length"].mean(),
        "num_words": data.groupby(by = "frequency").size()
    })
    
    return(sub_data)
summarize_text(German, text)

____________________________________________________________________________________________________________________________

Exercise 6

In this exercise, we will plot our results and look for differences across each translation.

colors = {"Portuguese": "green", "English": "blue", "German": "red"}
markers = {"frequent": "o","infrequent": "s", "unique": "^"}
import matplotlib.pyplot as plt
for i in range(grouped_data.shape[0]):
    row = grouped_data.iloc[i]
    plt.plot(row.mean_word_length, row.num_words,
        marker=markers[row.frequency],
        color = colors[row.language],
        markersize = 10
    )

color_legend = []
marker_legend = []
for color in colors:
    color_legend.append(
        plt.plot([], [],
        color=colors[color],
        marker="o",
        label = color, markersize = 10, linestyle="None")
    )
for marker in markers:
    marker_legend.append(
        plt.plot([], [],
        color="k",
        marker=markers[marker],
        label = marker, markersize = 10, linestyle="None")
    )
plt.legend(numpoints=1, loc = "upper left")

plt.xlabel("Mean Word Length")
plt.ylabel("Number of Words")

language,text = hamlet.iloc[2]

counted_text = count_words_fast(text)
unique_word = counted_text.keys()
counts_d = counted_text.values()

#Making the dataframe
data = pd.DataFrame.from_dict(counted_text, orient="index").reset_index()
data.columns = ['word', 'count']
data["length"]=list(map(len,data["word"]))

def word_frequency(count):
    if (count>10):
        frequency="frequent"
    elif(1<count<=10):
        frequency="infrequent"
    else:
        frequency="unique"
    return(frequency)


data["frequency"]=list(map(word_frequency,data["count"]))
a = data["frequency"]
